{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZPavlo/ML_projects/blob/master/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umdCSy2Z2ZMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMRREVaVkBG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCH_SIZE = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoBviLuDjxk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data_or = np.array([\n",
        "                    [0.0, 0.0],\n",
        "                    [0.0, 1.0],\n",
        "                    [1.0, 0.0],\n",
        "                    [1.0, 1.0],\n",
        "]).astype(\"float32\")\n",
        "true_out_data_or = np.array([0.0, 1.0, 1.0, 1.0]).astype(\"float32\").T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFGuHMbckqby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "from torch.optim import SGD\n",
        "\n",
        "# Perceptron\n",
        "perceptron = nn.Sequential(nn.Linear(2, 1))\n",
        "perceptron.train()\n",
        "\n",
        "optim = SGD(perceptron.parameters(), lr=0.02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZVTec-Uhjmu",
        "colab_type": "code",
        "outputId": "9cbeffa9-35a4-438b-8855-0f3a171e00c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# Perceptron train\n",
        "for ep in range(EPOCH_SIZE):\n",
        "\n",
        "    optim.zero_grad()\n",
        "    data = torch.from_numpy(input_data_or)\n",
        "    data.requires_grad_(True)\n",
        "    gt_out = torch.from_numpy(true_out_data_or).view(-1,1)\n",
        "\n",
        "    out = perceptron(data)\n",
        "    loss = ((out - gt_out) ** 2).sum()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if ep % 5 == 0:\n",
        "        print(\"eposh: {}, loss {}\".format(ep, loss.item()))\n",
        "print(\"Finish\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eposh: 0, loss 7.2135114669799805\n",
            "eposh: 5, loss 0.9173276424407959\n",
            "eposh: 10, loss 0.4859866201877594\n",
            "eposh: 15, loss 0.39696204662323\n",
            "eposh: 20, loss 0.3479759395122528\n",
            "eposh: 25, loss 0.3157680034637451\n",
            "eposh: 30, loss 0.2942357361316681\n",
            "eposh: 35, loss 0.27980679273605347\n",
            "eposh: 40, loss 0.2701248526573181\n",
            "eposh: 45, loss 0.26361867785453796\n",
            "eposh: 50, loss 0.2592394948005676\n",
            "eposh: 55, loss 0.2562864422798157\n",
            "eposh: 60, loss 0.25429099798202515\n",
            "eposh: 65, loss 0.25293925404548645\n",
            "eposh: 70, loss 0.2520211637020111\n",
            "eposh: 75, loss 0.25139570236206055\n",
            "eposh: 80, loss 0.25096818804740906\n",
            "eposh: 85, loss 0.2506749629974365\n",
            "eposh: 90, loss 0.2504730224609375\n",
            "eposh: 95, loss 0.2503332495689392\n",
            "eposh: 100, loss 0.2502361834049225\n",
            "eposh: 105, loss 0.2501683235168457\n",
            "eposh: 110, loss 0.2501206398010254\n",
            "eposh: 115, loss 0.2500869929790497\n",
            "eposh: 120, loss 0.2500631511211395\n",
            "eposh: 125, loss 0.2500460743904114\n",
            "eposh: 130, loss 0.25003379583358765\n",
            "eposh: 135, loss 0.2500249147415161\n",
            "eposh: 140, loss 0.25001847743988037\n",
            "eposh: 145, loss 0.2500138282775879\n",
            "eposh: 150, loss 0.25001031160354614\n",
            "eposh: 155, loss 0.25000765919685364\n",
            "eposh: 160, loss 0.250005841255188\n",
            "eposh: 165, loss 0.25000444054603577\n",
            "eposh: 170, loss 0.2500033378601074\n",
            "eposh: 175, loss 0.25000256299972534\n",
            "eposh: 180, loss 0.2500019669532776\n",
            "eposh: 185, loss 0.2500014901161194\n",
            "eposh: 190, loss 0.2500011622905731\n",
            "eposh: 195, loss 0.25000089406967163\n",
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i88aDGTi6Yh6",
        "colab_type": "code",
        "outputId": "94a7e9ce-9978-4c42-cf8f-6bae140ab709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "test_data = torch.from_numpy(input_data_or)\n",
        "for d in test_data:\n",
        "    out = int(perceptron(d.unsqueeze(0)).item() > 0.5)\n",
        "    d = [int(p) for p in d]\n",
        "    print(\"input {} : output {}\".format(d, out))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [0, 0] : output 0\n",
            "input [0, 1] : output 1\n",
            "input [1, 0] : output 1\n",
            "input [1, 1] : output 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCiYDU29ery9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data_xor = np.array([\n",
        "                    [0.0, 0.0],\n",
        "                    [0.0, 1.0],\n",
        "                    [1.0, 0.0],\n",
        "                    [1.0, 1.0],\n",
        "]).astype(\"float32\")\n",
        "true_out_data_xor = np.array([0.0, 1.0, 1.0, 0.0]).astype(\"float32\").T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL_ozF-wfA8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "from torch.optim import SGD\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.normal_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "# Multi Perceptron\n",
        "multi_perceptron = nn.Sequential(nn.Linear(2, 3), nn.ReLU(), nn.Linear(3, 1), nn.Sigmoid())\n",
        "multi_perceptron.train()\n",
        "multi_perceptron.apply(init_weights)\n",
        "\n",
        "optim = SGD(multi_perceptron.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9veum9Sf2bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "32a35bc4-8f01-4827-8a32-0afd2a9e7bf5"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# Multi Perceptron train\n",
        "crit = nn.BCELoss()\n",
        "for ep in range(EPOCH_SIZE * 100):\n",
        "\n",
        "    optim.zero_grad()\n",
        "    data = torch.from_numpy(input_data_xor)\n",
        "    data.requires_grad_(True)\n",
        "    gt_out = torch.from_numpy(true_out_data_xor).view(-1,1)\n",
        "\n",
        "    out = multi_perceptron(data)\n",
        "    \n",
        "    loss = crit(out, gt_out)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if ep % 500 == 0:\n",
        "        print(\"eposh: {}, loss {}\".format(ep, loss.item()))\n",
        "print(\"Finish\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eposh: 0, loss 0.5568562746047974\n",
            "eposh: 500, loss 0.054581306874752045\n",
            "eposh: 1000, loss 0.022020984441041946\n",
            "eposh: 1500, loss 0.013273844495415688\n",
            "eposh: 2000, loss 0.009392381645739079\n",
            "eposh: 2500, loss 0.007216223515570164\n",
            "eposh: 3000, loss 0.005839431658387184\n",
            "eposh: 3500, loss 0.004893375560641289\n",
            "eposh: 4000, loss 0.004204161930829287\n",
            "eposh: 4500, loss 0.00368123478256166\n",
            "eposh: 5000, loss 0.00327071500942111\n",
            "eposh: 5500, loss 0.002940922975540161\n",
            "eposh: 6000, loss 0.002670946065336466\n",
            "eposh: 6500, loss 0.0024446314200758934\n",
            "eposh: 7000, loss 0.0022517573088407516\n",
            "eposh: 7500, loss 0.002087806351482868\n",
            "eposh: 8000, loss 0.001945217838510871\n",
            "eposh: 8500, loss 0.0018204819643869996\n",
            "eposh: 9000, loss 0.0017103030113503337\n",
            "eposh: 9500, loss 0.0016123291570693254\n",
            "eposh: 10000, loss 0.0015250613214448094\n",
            "eposh: 10500, loss 0.0014463759725913405\n",
            "eposh: 11000, loss 0.0013754782266914845\n",
            "eposh: 11500, loss 0.0013109329156577587\n",
            "eposh: 12000, loss 0.0012522453907877207\n",
            "eposh: 12500, loss 0.00119811634067446\n",
            "eposh: 13000, loss 0.0011486480943858624\n",
            "eposh: 13500, loss 0.0011029148008674383\n",
            "eposh: 14000, loss 0.0010605724528431892\n",
            "eposh: 14500, loss 0.0010215156944468617\n",
            "eposh: 15000, loss 0.0009850725764408708\n",
            "eposh: 15500, loss 0.0009510490926913917\n",
            "eposh: 16000, loss 0.0009192207362502813\n",
            "eposh: 16500, loss 0.0008894826751202345\n",
            "eposh: 17000, loss 0.0008615661645308137\n",
            "eposh: 17500, loss 0.0008352918084710836\n",
            "eposh: 18000, loss 0.0008105851011350751\n",
            "eposh: 18500, loss 0.0007871622801758349\n",
            "eposh: 19000, loss 0.0007652320200577378\n",
            "eposh: 19500, loss 0.0007442573551088572\n",
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfDEbBfegLvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a0523563-23f8-4648-d034-56346a1348f0"
      },
      "source": [
        "test_data = torch.from_numpy(input_data_xor)\n",
        "multi_perceptron.eval()\n",
        "for d in test_data:\n",
        "    out = int(multi_perceptron(d.unsqueeze(0)).item() > 0.5)\n",
        "    d = [int(p) for p in d]\n",
        "    print(\"input {} : output {}\".format(d, out))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [0, 0] : output 0\n",
            "input [0, 1] : output 1\n",
            "input [1, 0] : output 1\n",
            "input [1, 1] : output 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}