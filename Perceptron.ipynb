{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZPavlo/ML_projects/blob/master/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umdCSy2Z2ZMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMRREVaVkBG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCH_SIZE = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoBviLuDjxk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data_or = np.array([\n",
        "                    [0.0, 0.0],\n",
        "                    [0.0, 1.0],\n",
        "                    [1.0, 0.0],\n",
        "                    [1.0, 1.0],\n",
        "]).astype(\"float32\")\n",
        "true_out_data_or = np.array([0.0, 1.0, 1.0, 1.0]).astype(\"float32\").T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFGuHMbckqby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "from torch.optim import SGD\n",
        "\n",
        "# Perceptron\n",
        "perceptron = nn.Sequential(nn.Linear(2, 1))\n",
        "perceptron.train()\n",
        "\n",
        "optim = SGD(perceptron.parameters(), lr=0.02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZVTec-Uhjmu",
        "colab_type": "code",
        "outputId": "240baafc-f963-4910-c630-ea5a577420b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# Perceptron train\n",
        "for ep in range(EPOCH_SIZE):\n",
        "\n",
        "    optim.zero_grad()\n",
        "    data = torch.from_numpy(input_data_or)\n",
        "    data.requires_grad_(True)\n",
        "    gt_out = torch.from_numpy(true_out_data_or).view(-1,1)\n",
        "\n",
        "    out = perceptron(data)\n",
        "    loss = ((out - gt_out) ** 2).sum()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if ep % 5 == 0:\n",
        "        print(\"eposh: {}, loss {}\".format(ep, loss.item()))\n",
        "print(\"Finish\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eposh: 0, loss 3.51870059967041\n",
            "eposh: 5, loss 0.4546528160572052\n",
            "eposh: 10, loss 0.28332772850990295\n",
            "eposh: 15, loss 0.2675912082195282\n",
            "eposh: 20, loss 0.262115478515625\n",
            "eposh: 25, loss 0.25858962535858154\n",
            "eposh: 30, loss 0.256136417388916\n",
            "eposh: 35, loss 0.25441044569015503\n",
            "eposh: 40, loss 0.25318869948387146\n",
            "eposh: 45, loss 0.2523189187049866\n",
            "eposh: 50, loss 0.25169599056243896\n",
            "eposh: 55, loss 0.2512471079826355\n",
            "eposh: 60, loss 0.25092196464538574\n",
            "eposh: 65, loss 0.25068485736846924\n",
            "eposh: 70, loss 0.2505110800266266\n",
            "eposh: 75, loss 0.25038301944732666\n",
            "eposh: 80, loss 0.2502882182598114\n",
            "eposh: 85, loss 0.25021758675575256\n",
            "eposh: 90, loss 0.25016480684280396\n",
            "eposh: 95, loss 0.2501252293586731\n",
            "eposh: 100, loss 0.250095397233963\n",
            "eposh: 105, loss 0.2500728964805603\n",
            "eposh: 110, loss 0.250055730342865\n",
            "eposh: 115, loss 0.2500426769256592\n",
            "eposh: 120, loss 0.2500327527523041\n",
            "eposh: 125, loss 0.2500251829624176\n",
            "eposh: 130, loss 0.2500193417072296\n",
            "eposh: 135, loss 0.25001493096351624\n",
            "eposh: 140, loss 0.2500114440917969\n",
            "eposh: 145, loss 0.25000882148742676\n",
            "eposh: 150, loss 0.25000685453414917\n",
            "eposh: 155, loss 0.2500053346157074\n",
            "eposh: 160, loss 0.2500040829181671\n",
            "eposh: 165, loss 0.25000321865081787\n",
            "eposh: 170, loss 0.2500024735927582\n",
            "eposh: 175, loss 0.25000184774398804\n",
            "eposh: 180, loss 0.250001460313797\n",
            "eposh: 185, loss 0.2500012218952179\n",
            "eposh: 190, loss 0.25000089406967163\n",
            "eposh: 195, loss 0.2500007152557373\n",
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i88aDGTi6Yh6",
        "colab_type": "code",
        "outputId": "03c91322-2dc3-488e-e761-af37bc7dfcfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "test_data = torch.from_numpy(input_data_or)\n",
        "for d in test_data:\n",
        "    out = int(perceptron(d.unsqueeze(0)).item() > 0.5)\n",
        "    d = [int(p) for p in d]\n",
        "    print(\"input {} : output {}\".format(d, out))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [0, 0] : output 0\n",
            "input [0, 1] : output 1\n",
            "input [1, 0] : output 1\n",
            "input [1, 1] : output 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCiYDU29ery9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data_xor = np.array([\n",
        "                    [0.0, 0.0],\n",
        "                    [0.0, 1.0],\n",
        "                    [1.0, 0.0],\n",
        "                    [1.0, 1.0],\n",
        "]).astype(\"float32\")\n",
        "true_out_data_xor = np.array([0.0, 1.0, 1.0, 0.0]).astype(\"float32\").T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL_ozF-wfA8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5138ee13-d4b9-438e-c9d3-af2a02a455ac"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "from torch.optim import SGD\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "# Multi Perceptron\n",
        "multi_perceptron = nn.Sequential(nn.Linear(2, 3, bias=True), nn.ReLU(), nn.Linear(3, 1, bias=True), nn.Sigmoid())\n",
        "multi_perceptron.train()\n",
        "multi_perceptron.apply(init_weights)\n",
        "\n",
        "optim = SGD(multi_perceptron.parameters(), lr=0.1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9veum9Sf2bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "b16c5fd8-4490-46a5-c8dd-61c87d96a711"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# Multi Perceptron train\n",
        "crit = nn.BCELoss()\n",
        "for ep in range(EPOCH_SIZE * 100):\n",
        "\n",
        "    optim.zero_grad()\n",
        "    data = torch.from_numpy(input_data_xor)\n",
        "    data.requires_grad_(True)\n",
        "    gt_out = torch.from_numpy(true_out_data_xor).view(-1,1)\n",
        "\n",
        "    out = multi_perceptron(data)\n",
        "    # loss = ((out - gt_out) ** 2).sum()\n",
        "    loss = crit(out, gt_out)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if ep % 500 == 0:\n",
        "        print(\"eposh: {}, loss {}\".format(ep, loss.item()))\n",
        "print(\"Finish\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eposh: 0, loss 0.686728298664093\n",
            "eposh: 500, loss 0.07117527723312378\n",
            "eposh: 1000, loss 0.017894914373755455\n",
            "eposh: 1500, loss 0.008926360867917538\n",
            "eposh: 2000, loss 0.0056451465934515\n",
            "eposh: 2500, loss 0.004027139861136675\n",
            "eposh: 3000, loss 0.0030841673724353313\n",
            "eposh: 3500, loss 0.0024744553957134485\n",
            "eposh: 4000, loss 0.0020529688335955143\n",
            "eposh: 4500, loss 0.0017454144544899464\n",
            "eposh: 5000, loss 0.0015124435303732753\n",
            "eposh: 5500, loss 0.00133043946698308\n",
            "eposh: 6000, loss 0.0011849296279251575\n",
            "eposh: 6500, loss 0.0010661465348675847\n",
            "eposh: 7000, loss 0.0009674071916379035\n",
            "eposh: 7500, loss 0.0008843168616294861\n",
            "eposh: 8000, loss 0.0008134539239108562\n",
            "eposh: 8500, loss 0.0007523830863647163\n",
            "eposh: 9000, loss 0.0006992525304667652\n",
            "eposh: 9500, loss 0.0006527329096570611\n",
            "eposh: 10000, loss 0.0006115255528129637\n",
            "eposh: 10500, loss 0.0005749435513280332\n",
            "eposh: 11000, loss 0.0005421958048827946\n",
            "eposh: 11500, loss 0.000512730039190501\n",
            "eposh: 12000, loss 0.0004861433699261397\n",
            "eposh: 12500, loss 0.0004619731043931097\n",
            "eposh: 13000, loss 0.00043990599806420505\n",
            "eposh: 13500, loss 0.0004198075912427157\n",
            "eposh: 14000, loss 0.00040127523243427277\n",
            "eposh: 14500, loss 0.0003842640435323119\n",
            "eposh: 15000, loss 0.0003685055999085307\n",
            "eposh: 15500, loss 0.000353940122295171\n",
            "eposh: 16000, loss 0.000340373779181391\n",
            "eposh: 16500, loss 0.0003277766809333116\n",
            "eposh: 17000, loss 0.0003160146006848663\n",
            "eposh: 17500, loss 0.00030501303263008595\n",
            "eposh: 18000, loss 0.0002946972963400185\n",
            "eposh: 18500, loss 0.0002850227174349129\n",
            "eposh: 19000, loss 0.000275914731901139\n",
            "eposh: 19500, loss 0.00026735838036984205\n",
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfDEbBfegLvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2c3303b4-f450-4513-c4ce-0142dc2129d4"
      },
      "source": [
        "test_data = torch.from_numpy(input_data_xor)\n",
        "multi_perceptron.eval()\n",
        "for d in test_data:\n",
        "    out = int(multi_perceptron(d.unsqueeze(0)).item() > 0.5)\n",
        "    d = [int(p) for p in d]\n",
        "    print(\"input {} : output {}\".format(d, out))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [0, 0] : output 0\n",
            "input [0, 1] : output 1\n",
            "input [1, 0] : output 1\n",
            "input [1, 1] : output 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}